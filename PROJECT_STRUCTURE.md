# Project Structure Documentation

## ğŸ“‚ Directory Structure

```
rag_based_ai/
â”‚
â”œâ”€â”€ ğŸ“„ run.py                    # Main entry point - Start the application here
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore               # Git ignore patterns
â”œâ”€â”€ ğŸ“„ README.md                # Complete project documentation
â”‚
â”œâ”€â”€ ğŸ“ app/                     # Main Flask application package
â”‚   â”œâ”€â”€ __init__.py             # App factory & initialization logic
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ routes/              # Blueprint routes (URL handlers)
â”‚   â”‚   â”œâ”€â”€ __init__.py         # Routes package exports
â”‚   â”‚   â”œâ”€â”€ main.py             # Main web routes (/, /videos/<path>)
â”‚   â”‚   â””â”€â”€ api.py              # API endpoints (/api/*)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ services/            # Business logic layer
â”‚   â”‚   â”œâ”€â”€ __init__.py         # Services package exports
â”‚   â”‚   â”œâ”€â”€ embedding_service.py    # Ollama embedding operations
â”‚   â”‚   â”œâ”€â”€ llm_service.py          # Ollama LLM operations
â”‚   â”‚   â””â”€â”€ query_service.py        # RAG query processing
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/               # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py         # Utils package exports
â”‚   â”‚   â””â”€â”€ helpers.py          # Helper functions (timestamps, URLs)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ static/              # Static assets (served by Flask)
â”‚   â”‚   â””â”€â”€ style.css           # Application CSS styles
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ templates/           # Jinja2 HTML templates
â”‚       â””â”€â”€ index.html          # Main web interface
â”‚
â”œâ”€â”€ ğŸ“ config/                  # Configuration package
â”‚   â”œâ”€â”€ __init__.py             # Config package exports
â”‚   â””â”€â”€ settings.py             # Application settings & constants
â”‚
â”œâ”€â”€ ğŸ“ scripts/                 # Data preprocessing scripts
â”‚   â”œâ”€â”€ README.md               # Scripts documentation
â”‚   â”œâ”€â”€ youtube_downloader.py   # Download YouTube videos
â”‚   â”œâ”€â”€ extract_audio.py        # Audio extraction utility
â”‚   â”œâ”€â”€ video_to_mp3.py         # Convert videos to MP3
â”‚   â”œâ”€â”€ mp3_to_json.py          # Transcribe audio with Whisper
â”‚   â”œâ”€â”€ speech_to_text.py       # Alternative speech-to-text
â”‚   â”œâ”€â”€ preprocess_json.py      # Generate embeddings
â”‚   â”œâ”€â”€ create_video_mapping.py # Create video URL mappings
â”‚   â”œâ”€â”€ process_incoming.py     # CLI query interface
â”‚   â””â”€â”€ video_urls.txt          # Input: List of YouTube URLs
â”‚
â”œâ”€â”€ ğŸ“ data/                    # Data storage (generated files)
â”‚   â”œâ”€â”€ embeddings_df.joblib    # Serialized embeddings DataFrame
â”‚   â”œâ”€â”€ video_mapping.json      # Video number to YouTube URL mapping
â”‚   â””â”€â”€ output.json             # Processed output data
â”‚
â”œâ”€â”€ ğŸ“ videos/                  # Downloaded YouTube videos
â”œâ”€â”€ ğŸ“ audios/                  # Extracted audio files (MP3)
â”œâ”€â”€ ğŸ“ jsons/                   # Transcription JSON files
â””â”€â”€ ğŸ“ torch_env/               # Python virtual environment
```

---

## ğŸ—ï¸ Architecture Overview

### Separation of Concerns

The project follows a **modular architecture** with clear separation:

1. **Presentation Layer** (`app/routes/`)
   - Handles HTTP requests/responses
   - Routes user requests to appropriate services
   - Returns formatted responses

2. **Business Logic Layer** (`app/services/`)
   - Core RAG functionality
   - Embedding generation
   - LLM inference
   - Query processing

3. **Utility Layer** (`app/utils/`)
   - Reusable helper functions
   - Format conversions
   - URL generation

4. **Configuration Layer** (`config/`)
   - Centralized settings
   - Environment variables
   - Path management

5. **Data Processing Layer** (`scripts/`)
   - Independent preprocessing scripts
   - Data pipeline stages
   - One-time setup tasks

---

## ğŸ”„ Application Flow

### Startup Flow
```
run.py
  â””â”€> create_app() in app/__init__.py
       â”œâ”€> Load configuration from config/settings.py
       â”œâ”€> Load embeddings from data/embeddings_df.joblib
       â”œâ”€> Load video mapping from data/video_mapping.json
       â”œâ”€> Initialize QueryService
       â”œâ”€> Register blueprints (main_bp, api_bp)
       â””â”€> Start Flask server
```

### Request Flow (Query Processing)
```
User Query (Web UI)
  â””â”€> POST /api/query (app/routes/api.py)
       â””â”€> query_service.process_query()
            â”œâ”€> embedding_service.create_embedding()
            â”œâ”€> Calculate cosine similarity
            â”œâ”€> Get top K relevant chunks
            â”œâ”€> llm_service.build_rag_prompt()
            â”œâ”€> llm_service.generate_response()
            â””â”€> Return formatted response with chunks
```

---

## ğŸ“¦ Package Responsibilities

### `app/` - Main Application
- **Purpose**: Flask application with all web interface logic
- **Key Files**:
  - `__init__.py`: App factory, initialization, data loading
  - Entry point for the Flask application

### `app/routes/` - Route Handlers
- **Purpose**: HTTP endpoint definitions (URL â†’ Function mapping)
- **Files**:
  - `main.py`: Web page routes (`/`, `/videos/<path>`)
  - `api.py`: REST API routes (`/api/query`, `/api/health`, `/api/stats`)

### `app/services/` - Business Logic
- **Purpose**: Core functionality separated from HTTP layer
- **Files**:
  - `embedding_service.py`: Generate embeddings via Ollama
  - `llm_service.py`: LLM inference and prompt building
  - `query_service.py`: RAG pipeline orchestration

### `app/utils/` - Helpers
- **Purpose**: Reusable utility functions
- **Files**:
  - `helpers.py`: Timestamp formatting, YouTube URL generation

### `config/` - Configuration
- **Purpose**: Centralized settings management
- **Files**:
  - `settings.py`: All configurable parameters (paths, models, timeouts)

### `scripts/` - Data Pipeline
- **Purpose**: Independent data preprocessing scripts
- **Usage**: Run manually to prepare data
- **Note**: Scripts can be run from scripts directory, paths are handled automatically

### `data/` - Processed Data
- **Purpose**: Storage for generated data files
- **Files**:
  - `embeddings_df.joblib`: Pre-computed embeddings
  - `video_mapping.json`: Video ID to YouTube URL mapping

---

## ğŸš€ Running the Application

### Development Server
```bash
# Activate virtual environment
torch_env\Scripts\activate  # Windows
# source torch_env/bin/activate  # Linux/macOS

# Start the server
python run.py

# Access at: http://localhost:5000
```

### Production Deployment
```bash
# Use a production WSGI server
pip install gunicorn

# Run with Gunicorn (Linux/macOS)
gunicorn -w 4 -b 0.0.0.0:5000 'app:create_app()'

# Or use waitress (Windows compatible)
pip install waitress
waitress-serve --host=0.0.0.0 --port=5000 app:create_app
```

---

## ğŸ”§ Configuration

All configuration is centralized in `config/settings.py`:

```python
# Change these values to customize behavior
OLLAMA_BASE_URL = 'http://localhost:11434'
OLLAMA_EMBEDDING_MODEL = 'bge-m3'
OLLAMA_LLM_MODEL = 'llama3.2'
TOP_K_RESULTS = 7
```

**No need to modify code** - just update `config/settings.py`!

---

## ğŸ§ª Testing Individual Components

### Test Embedding Service
```python
from app.services import EmbeddingService

service = EmbeddingService()
embeddings = service.create_embedding(["test text"])
print(embeddings)
```

### Test LLM Service
```python
from app.services import LLMService

service = LLMService()
response = service.generate_response("What is AI?")
print(response)
```

### Test Query Service
```python
import joblib
from app.services import QueryService

embeddings_df = joblib.load('data/embeddings_df.joblib')
video_mapping = {}  # Load from JSON
service = QueryService(embeddings_df, video_mapping)
result = service.process_query("How to use AI?")
print(result)
```

---

## ğŸ” Code Organization Benefits

âœ… **Modularity**: Each component has a single responsibility  
âœ… **Testability**: Easy to test individual services  
âœ… **Maintainability**: Clear structure makes updates simple  
âœ… **Scalability**: Easy to add new routes or services  
âœ… **Reusability**: Services can be used independently  
âœ… **Configuration**: Centralized settings management  
âœ… **Best Practices**: Follows Flask application factory pattern  

---

## ğŸ“ Adding New Features

### Add a New API Endpoint
1. Define route in `app/routes/api.py`
2. Add business logic to appropriate service
3. Update configuration if needed

### Add a New Service
1. Create new file in `app/services/`
2. Implement service class
3. Export from `app/services/__init__.py`
4. Use in routes or other services

### Add New Configuration
1. Add parameter to `config/settings.py`
2. Use via `from config import Config`
3. Access as `Config.PARAMETER_NAME`

---

## ğŸ› Debugging

### Check Application State
```python
from app import get_app_state

state = get_app_state()
print(f"Embeddings loaded: {state['embeddings_df'] is not None}")
print(f"Videos mapped: {len(state['video_mapping'])}")
```

### Enable Flask Debug Mode
- Already enabled in `config/settings.py`: `DEBUG = True`
- Shows detailed error pages
- Auto-reloads on code changes

### Check Logs
- Flask logs appear in terminal where you ran `python run.py`
- Look for startup messages about embeddings and Ollama connection

---

## ğŸ“š Related Documentation

- **README.md**: Complete usage guide and setup instructions
- **scripts/README.md**: Data preprocessing pipeline documentation
- **config/settings.py**: All configurable parameters with comments

---

**This structure follows industry best practices for Flask applications and provides a solid foundation for growth and maintenance.**

