### 2. **Directory Structure**
   ```
   rag_based_ai/
   â”œâ”€â”€ run.py              # ğŸ†• Clean entry point
   â”œâ”€â”€ app/                # ğŸ†• Flask application package
   â”‚   â”œâ”€â”€ routes/         # ğŸ†• URL handlers (blueprints)
   â”‚   â”œâ”€â”€ services/       # ğŸ†• Business logic
   â”‚   â”œâ”€â”€ utils/          # ğŸ†• Helper functions
   â”‚   â”œâ”€â”€ static/         # âœ… Moved from root
   â”‚   â””â”€â”€ templates/      # âœ… Moved from root
   â”œâ”€â”€ config/             # ğŸ†• Configuration management
   â”œâ”€â”€ scripts/            # âœ… Organized preprocessing scripts
   â””â”€â”€ data/               # âœ… Centralized data storage
   ```

### 4. **Centralized Configuration**
   - All settings in `config/settings.py`
   - Easy to modify without code changes
   - Environment-aware setup ready

### 5. **Organized Scripts**
   - Moved all preprocessing scripts to `scripts/`
   - Updated paths to work from any directory
   - Added comprehensive scripts documentation

---

## ğŸ“‚ File Organization

### Before (Monolithic)
```
app.py 
â”œâ”€â”€ Flask app setup
â”œâ”€â”€ Data loading functions
â”œâ”€â”€ Embedding service
â”œâ”€â”€ LLM service
â”œâ”€â”€ Query processing
â”œâ”€â”€ All route handlers
â””â”€â”€ Main execution
```

### After (Modular)
```
run.py                               # Entry point
app/__init__.py                      # App factory
app/routes/main.py                   # Web routes
app/routes/api.py                    # API routes
app/services/embedding_service.py    # Embeddings
app/services/llm_service.py          # LLM inference
app/services/query_service.py        # RAG logic
app/utils/helpers.py                 # Utilities
config/settings.py                   # Configuration
```

---

## ğŸš€ How to Use

### Start the Application
```bash
# 1. Activate virtual environment
torch_env\Scripts\activate

# 2. Run the application
python run.py

# 3. Open browser
# http://localhost:5000
```

### Modify Configuration
Edit `config/settings.py`:
```python
# Change models
OLLAMA_EMBEDDING_MODEL = 'bge-m3'
OLLAMA_LLM_MODEL = 'llama3.2'

# Change settings
TOP_K_RESULTS = 7
PORT = 5000
```

### Run Scripts
```bash
python scripts/preprocess_json.py
python scripts/create_video_mapping.py
```

## ğŸ“ Important Files

| File | Purpose |
|------|---------|
| `run.py` | Main entry point to start the app |
| `app/__init__.py` | Flask app factory and initialization |
| `config/settings.py` | All configuration in one place |
| `requirements.txt` | Python dependencies |

---

## ğŸ”§ Configuration Options

All in `config/settings.py`:

```python
# Flask
DEBUG = True
HOST = '0.0.0.0'
PORT = 5000

# Ollama
OLLAMA_BASE_URL = 'http://localhost:11434'
OLLAMA_EMBEDDING_MODEL = 'bge-m3'
OLLAMA_LLM_MODEL = 'llama3.2'

# RAG
TOP_K_RESULTS = 5

# Paths (auto-managed)
DATA_DIR = BASE_DIR / 'data'
VIDEOS_DIR = BASE_DIR / 'videos'
# ... and more
```

---

## âœ¨ Next Steps

1. **Test the Application**
   ```bash
   python run.py
   # Visit http://localhost:5000
   ```

3. **Customize Configuration**
   - Edit `config/settings.py` as needed
   - No code changes required!

4. **Add New Features**
   - New routes â†’ `app/routes/`
   - New services â†’ `app/services/`
   - New utilities â†’ `app/utils/`

5. **Deploy to Production**
   - Use Gunicorn or Waitress
   - Environment variables for secrets
   - Production-ready structure!

---

## ğŸ“ Learning Resources

- **Flask Application Factory**: [Flask Docs](https://flask.palletsprojects.com/en/latest/patterns/appfactories/)
- **Blueprints**: [Flask Blueprints](https://flask.palletsprojects.com/en/latest/blueprints/)
- **Project Structure**: [Flask Best Practices](https://flask.palletsprojects.com/en/latest/tutorial/layout/)

---

## ğŸ› Troubleshooting

### Application won't start
```bash
# Check you're in project root
pwd  # Should show: .../rag_based_ai

# Activate virtual environment
torch_env\Scripts\activate

# Check Ollama is running
curl http://localhost:11434/api/tags
```

### Import errors
```bash
# Ensure virtual environment is activated
# Should see (torch_env) in prompt
```

### Scripts not working
```bash
# Scripts handle paths automatically
python scripts/script_name.py  # From project root
# OR
cd scripts && python script_name.py
```

**Happy coding! ğŸš€**

